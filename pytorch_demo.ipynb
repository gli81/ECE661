{"cells":[{"cell_type":"markdown","metadata":{"id":"ZxszbkSGJfhr"},"source":["# ECE661 PyTorch Demo: Train an MNIST Classifier\n","\n","In this tutorial, we will step through the process of training and testing a simple MNIST classifier with PyTorch. Feel free to modify hyperparameters, add `print` statements, and experiment with the base code.\n","\n","You can use this as a reference, but please **DO NOT** copy code directly for your assignments.\n","\n","## Imports\n","Start by importing the necessary PyTorch modules."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vsr4gqf0Jfhv"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","from torchvision import datasets, transforms\n","\n","print(\"PyTorch version:\", torch.__version__)"]},{"cell_type":"markdown","metadata":{"id":"KGdl3gZMJfhx"},"source":["## Setup device\n","If GPUs (w/ CUDA) are available we will use them. If not, set the device to CPU. Initializing the `device` object this way makes the code system agnostic."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r98mEDdZJfhy"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device:\", device)"]},{"cell_type":"markdown","metadata":{"id":"g0XKJlzOJfhy"},"source":["## Define Model\n","Next, we will build a small custom CNN for MNIST digit classification.\n","\n","When building a model, we make it a sub-class of `nn.Module` and override two functions: `__init__` and `forward`:\n","- `__init__` is the model constructor. Here, we first call the parent's constructor then define our layers. This can be thought of as creating the nodes of our computational graph.\n","- `forward` defines the forward pass of our network. In other words, this defines the connections between the nodes (layers) of our computation graph. Must return a tensor.\n","\n","Keep in mind that there are many ways to define a PyTorch model based on user preference. For example, you can combine blocks using PyTorch's [Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) interface. Another user choice is whether to define layers as `nn.Module` objects or to manually instantiate weight tensors and use the `nn.functional` interface for added flexibility. The beauty of PyTorch is that it allows users to use a combination of the many interfaces in the same model.\n","\n","In this example, we use a common PyTorch model design pattern which is to construct layers that have associated learnable parameters (e.g., convolutional layers, fully connected layers) in the constructor (`__init__`), and use the `nn.functional` interface for layers that do not have learnable parameters (e.g., pooling layers, activation functions). Note, however, that defining the max pool layers in the constructor as `nn.MaxPool2d` objects will lead to _identical_ results.\n","\n","When defining your PyTorch model, always refer to the [PyTorch docs](https://pytorch.org/docs/stable/index.html) to assure that you are using the modules/functions correctly. As an example, check out the [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html?highlight=nn%20conv2d#torch.nn.Conv2d) page for a reference to the argument order, types and shapes that this module expects."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2yg623ufJfhz"},"outputs":[],"source":["# Define MyNet model class\n","class MyNet(nn.Module):\n","    def __init__(self):\n","        super(MyNet, self).__init__()\n","        # First conv layer should expect 1 input channel, as MNIST images are greyscale\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n","        # conv2's in_channels should match conv1's out_channels\n","        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n","        # Note that before passing conv2's output to fc1 we will flatten it\n","        # So the input size will be feature_depth*feature_height*feature_width \n","        # We can compute this by hand (note input is 1x28x28): 64x7x7=3136)\n","        self.fc1 = nn.Linear(in_features=(64*7*7), out_features=128)\n","        # This is the last FC layer, so the output size must == num_classes == 10\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        # Forward thru conv1\n","        x = self.conv1(x)\n","        # Apply ReLU activation on the output\n","        x = F.relu(x)\n","        # Downsample feature's spatial extent w/ max pool\n","        x = F.max_pool2d(x, kernel_size=2)\n","        \n","        # Forward thru conv2\n","        x = self.conv2(x)\n","        # Apply ReLU activation on the output\n","        x = F.relu(x)\n","        # Downsample feature's spatial extent w/ max pool\n","        x = F.max_pool2d(x, kernel_size=2)\n","        \n","        # Flatten conv feature here\n","        x = torch.flatten(x, 1)\n","        # Forward thru fc1\n","        x = self.fc1(x)\n","        # Apply ReLU activation on the output\n","        x = F.relu(x)\n","        # Forward thru fc2\n","        x = self.fc2(x)\n","        return x\n","    \n","\n","# Construct a MyNet instance on the correct device\n","model = MyNet().to(device)\n","# Print nodes in model's graph to check for correctness\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"gyZW6z03Jfh1"},"source":["## Initialize loss function and optimizer\n","\n","The next step is to initialize our loss function (`criterion`) and optimizer.\n","- For the `criterion` we use `nn.CrossEntropyLoss`, which combines `nn.LogSoftmax` with `nn.NLLLoss`.\n","- We use an `SGD` optimizer with learning rate 0.01."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SCJJxeNNJfh1"},"outputs":[],"source":["# Construct loss function object\n","criterion = nn.CrossEntropyLoss().to(device)\n","\n","# Construct optimizer\n","optimizer = optim.SGD(model.parameters(), lr=0.01)"]},{"cell_type":"markdown","metadata":{"id":"yWWn-wUBJfh2"},"source":["## Prepare data and data loading process\n","\n","In this example we are training an MNIST classifier. PyTorch provides easy access to popular benchmark datasets via [torchvision.datasets](https://pytorch.org/vision/stable/datasets.html#).\n","\n","Now that we have our model and learning criterion established, we can prepare the data and data loading process. The first step is to define our `transform` class where we define the input preprocessing that we desire for each input. In our case, we simply convert the data to a tensor and normalize the data about the precalculated mean and std of each channel in the training set (this can usually be looked up). \n","\n","The next step is to construct PyTorch `Datasets`, which stores the data in memory. We set the `download` flags to true, which will download the data to the specified path if PyTorch cannot find already find it there.\n","\n","We also need to construct a `DataLoader` for both the train and test `Dataset`. The role of the `DataLoader` is to wrap an iterable around the `Dataset` so that we can easily serve the data up in batches. This is where we set the batch size, and `shuffle` flag. Typically, we shuffle training data to help with convergence."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z4_gXv8LJfh3"},"outputs":[],"source":["# Define preprocessing\n","transform=transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n","        ])\n","\n","# Load data into datasets\n","train_dataset = datasets.MNIST('./', train=True, download=True, transform=transform)\n","test_dataset = datasets.MNIST('./', train=False, download=True, transform=transform)\n","\n","# Construct dataloaders\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"BWW7UyZpJfh3"},"source":["## [Optional] Visualize data\n","\n","Here we investigate what a batch of our training data looks like.\n","\n","Notice that our `images` tensor contains the normalized image data, and has shape NxCxHxW, and the `targets` tensor is essentially a list of corresponding target class labels with shape N (batch_size)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IcuIX5L3Jfh4"},"outputs":[],"source":["# Grab a batch of training data\n","images, targets = next(iter(train_loader))\n","# Print data tensors\n","print(\"images:\", images[0], images.shape)\n","print(\"targets:\", targets, targets.shape)\n","\n","# Plot grid of images\n","grid_img = torchvision.utils.make_grid(images, 8)\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","plt.figure(figsize = (10,10))\n","plt.imshow(grid_img.permute(1, 2, 0))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"bz2oXFYwJfh4"},"source":["## Train model\n","\n","Finally we can train our model. \n","\n","Training is typically done by looping over a specified number of epochs. In each epoch, we iterate over all batches of the training data and update the model. \n","\n","Note that for each batch, we must:\n","- Move data to correct device.\n","- Zero out old gradients (they accumulate by default).\n","- Forward pass input through model.\n","- Compute loss w.r.t. the current targets.\n","- Backward pass the loss to get compute gradients.\n","- Update parameters using gradients and our optimizer.\n","\n","We will also track average training loss and accuracy for each epoch."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-0XbZUkPJfh4"},"outputs":[],"source":["epochs = 3\n","\n","for i in range(1, epochs+1):\n","    # Put model in train mode\n","    model.train()\n","    print(\"\\nEpoch [{}/{}]\".format(i, epochs))\n","\n","    total_ims = 0\n","    total_batches = 0\n","    total_loss = 0\n","    total_corrects = 0\n","    \n","    # Train the training dataset for 1 epoch.\n","    for batch_idx, (images, targets) in enumerate(train_loader):\n","        # Copy inputs to device\n","        images = images.to(device)\n","        targets = targets.to(device)\n","        # Zero the gradients\n","        optimizer.zero_grad()\n","        # Forward pass images through model\n","        outputs = model(images)\n","        # Compute loss\n","        loss = criterion(outputs, targets)\n","        # Now backward loss\n","        loss.backward()\n","        # Apply gradient\n","        optimizer.step()\n","        # Calculate correct predictions\n","        _, predicted = torch.max(outputs, 1)\n","        #print(\"targets:\", targets, targets.shape)\n","        #print(\"predicted:\", predicted, predicted.shape)\n","        correct = predicted.eq(targets).sum()\n","        #print(\"correct:\", correct)\n","        # Append to totals\n","        total_ims += targets.shape[0]\n","        total_batches += 1\n","        total_loss += loss\n","        total_corrects += correct.item()\n","        # Print every 100 batches\n","        if batch_idx % 100 == 0:\n","            print(\"batch: {}\".format(batch_idx), \"\\tloss: {}\".format(loss.item()))\n","    \n","    avg_loss = total_loss / total_batches\n","    acc = (total_corrects / total_ims) * 100.0\n","    print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, acc))\n"]},{"cell_type":"markdown","metadata":{"id":"bhL_iZQUJfh5"},"source":["## Test model\n","\n","Now that we have a trained model, we can test its performance on the test set.\n","\n","To do this we use a similar loop to our training procedure, but we do not need to compute gradients or update the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yn5YMmFhJfh5"},"outputs":[],"source":["# Make this a function so we can re-use later (can do this for training too)\n","def test_model(model):\n","    total_ims = 0\n","    total_batches = 0\n","    total_loss = 0\n","    total_corrects = 0\n","\n","    # Put model in eval mode\n","    model.eval()\n","\n","    # Do NOT compute gradients\n","    with torch.no_grad():\n","        # Run inference on each image in the test set (use batches to make process faster)\n","        for batch_idx, (images, targets) in enumerate(test_loader):\n","            # Copy inputs to device\n","            images = images.to(device)\n","            targets = targets.to(device)\n","            # Forward pass images through model\n","            outputs = model(images)\n","            # Compute loss\n","            loss = criterion(outputs, targets)\n","            # Calculate correct predictions\n","            _, predicted = torch.max(outputs, 1)\n","            correct = predicted.eq(targets).sum()\n","            # Append to totals\n","            total_ims += targets.shape[0]\n","            total_batches += 1\n","            total_loss += loss\n","            total_corrects += correct.item()\n","\n","    avg_loss = total_loss / total_batches\n","    acc = (total_corrects / total_ims) * 100.0\n","    print(\"Test loss: %.4f, Test accuracy: %.4f\" %(avg_loss, acc))\n","\n","    \n","# Call test_model\n","test_model(model)"]},{"cell_type":"markdown","metadata":{"id":"x8cgYURQJfh6"},"source":["## Saving and loading models\n","\n","The last basic procedure that we will cover is how to save and load PyTorch models. \n","\n","In this example, we wish to save the model to disk to be used for inference later. To do this, we simply use `torch.save` to save the model's `state_dict`, which is a Python dictionary that contains all of the parameters of the module.\n","\n","\n","\n","For a detailed outline on the many ways to save and load models (e.g., save/load across devices, save/load for finetuning, etc.), see the [PyTorch tutorial](https://pytorch.org/tutorials/beginner/saving_loading_models.html). "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SOSPvJrqJfh6"},"outputs":[],"source":["# Save model\n","torch.save(model.state_dict(), \"./demo_model.pt\")"]},{"cell_type":"markdown","metadata":{"id":"K0HEuOscJfh6"},"source":["To demonstrate the loading process we will construct a new `MyNet` (randomly initialized), test it (without training), then load the saved parameters and re-test to prove that the parameters loaded correctly."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M-7BBLR1Jfh7"},"outputs":[],"source":["# Create new MyNet\n","model2 = MyNet().to(device)\n","\n","# Test un-trained model2\n","print(\"Before loading...\")\n","test_model(model2)\n","\n","# Load parameters\n","model2.load_state_dict(torch.load(\"./demo_model.pt\"))\n","model2.eval()  # Remember to set model to eval mode (train mode is default)\n","# Re-test un-trained model2\n","print(\"\\nAfter loading...\")\n","test_model(model2)"]},{"cell_type":"markdown","metadata":{"id":"fjqWuKB1Jfh7"},"source":["## Conclusion\n","\n","Congratulations, now you know the basics of PyTorch! \n","\n","Remember to use the [PyTorch docs](https://pytorch.org/docs/stable/index.html) to learn about new functions and to avoid silly mistakes. The [PyTorch discuss] forum is also a useful resource. \n","\n","Good luck!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8gNj7ao9Jfh7"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"pytorch_demo.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}